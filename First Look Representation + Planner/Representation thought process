So where should the actions in the world be defined. In PDDL, actions are object agnostic.

Actions should be methods in the Domain class

Make use of python's type system instead of PDDL


Ok so the key might be in how to make the planner actually iterate through and search different states

Ok so Python has a dynamic typing system. So the types are calculated at runtime, and have to deal with type exceptions as they occur. Making new types isnt really feasbilbe because baked into the programming language not really what we want

Ok so now start on the planner. Develop a set of valid actions for the current world.

Mkay so also gonna be interesting when they like vary the number of parameters for an action

Ok so right now just pretty dumb, gonna call its own functions and see if they work. If they do add to potential size of the tree. Then use some algo to specify which branches of the tree to go down first. Gonna need to abstract that away. Seems legit

Maybe later plug in someone else's pddl parser and have it generate sketchy python code as a demo workflow for this system??

https://www.geeksforgeeks.org/metaprogramming-metaclasses-python/

Metaprogramming for the win
http://dabeaz.com/py3meta/Py3Meta.pdf
Ok so learned about class decorators. Could use them to check arguments before they were getting applied to a function, but not that helpful

https://github.com/pucrs-automated-planning/pddl-parser 

Ok plan of action: 
Wrap the action methods in classes so that they include argument metadata. Group the objects in the world by their classes. Then for each new action method, iterate through all of the possible classes of those to generate planner's next actions.

Ok so now I need to be able to either reset the state every time which is inefficient, or just check that the predicates are satisfied. 

Ok I think I need to abstract the actions as subclasses of the domain. Have a validates predicates method, and type metadata for the arguments.


Want to abstract away object class and have it automatically add its name to the metadata. Also want to abstract out notion of Domain vs BlockTower. I also broke printstate w objects

For more generality, allow blocks to stack on themselves.

Want to get type grouping and iteration to work correctly

Ok so I want to write a planner and include the basic causal model step. The stackable property is the property that we want to update with the causal model. Also should be a property between two blocks in the system

How to generalize the search algorithm? Priority queue vs a normal queue in the search algorithm. 

How do I represent state? Well it is I guess just a specific domain object. 


Maybe fix object names vs objects, not sure I need to explicitly store their names, seems kindof hacky

How do I calculate the freaking heuristics??? Like need to know the result by doing the action every time, exactly the problem March was talking about


Todo:
Ok so for now, the getValidActions function I feel like should be generic to a domain with defined actions, however it isn't there yet, so it should maybe stay in the planner, also buddy need some docstrings

State is combination of action and variables?? Like can go back to same state but do different action?


Good programming technique, explain it out loud and whiteboard it

Interested to see how the planner in the library that March was talking about works because they would have had the same problem


Ok so I can do whatever the fuck I want.
So currently each node in the graph needs its own state representation. So instead of actions modifying a state in place, I want actions to be applied to a state, and change it

So a domain is simply a state and all the available actions on that state. This is for a start state and any other intermediary state. 

State is a list of object.

Domain contains a list of actions, checks if a given state is the goal

State is a collection of objects and other variables. Actions are applied to states, and return modified states

So for list of actions, I don't also need a list of their names, if they themselves contain their names. Like for error messages can just do action.name

So the reason why I stored all of the names is so I could do the eval trick, but that seems hacky, so I am going to try and fix it. 

First need to verify, that can just do object.doAction

Ok want to add get object by name from state functionality

Hmmmm. Actions need to be able to edit a state. But how specify which object in state as parameter? I think actual object itself should go in parameter, not just the name. Maybe strings is the better way to go... Then have to change object representation again

Ensure objects have names TODO

Ok so now the planner can do actions without knowing their name, and by passing in a state object.

Now need to iterate over all possible inputs to a given action and include metadata types to do the clever iteration I wanted to do, or maybe delay that for later -> MAYBE LATER

Ok litty, so the next actions thing works fully now

Fuck gonna need to generalize this to multiple numbers of parameters and types. Could generalize to taking in array rather than an actual set number of parameters, and each action does its own checking?

Unhashable list type Grr


Question about chaining actions
Reinforcement learning??

Cant use probabalistic PDDL because cannot update predicates from the visual perception at each action state

Want to look into and see how the probablistic pddl model plans, thanks littman


Ok so need to incorporate the causal model by generating a probability of taking a certain action given a state and a potential action

Ok for right now, ignore the seen list

I mean I guess just store the history of a node to each node we add to the nodes

Generalize for action types and number of parameters

Should also formalize the lists as actual classes and objects instead of just lists and shit. You know what? Why don't I just do that now

Ok need to think through how to actually sample stuff and what happens if there is no otehr valid action 

Ok so now I just need to incoporate the causal sampling step

Ok so maybe I want to write MonteCarloSearch.

Current search algorithm is just BFS for every possible move.

How incorporate probablistic information into the planner

"First, the optimal action choices for reaching a goal may be a function of the probabilistic outcomes along the way—a single sequence of actions may not be sufficient. As a result, it can be difficult to output a “plan”. For this reason, we decided not to separate plan synthesis and execution into two phases, but instead evaluated planners online." -> Bingo, we are doing the same thing

Probablistic PDDL allows changing of predicates probablistically. Key difference is that there is no way to integrate visual aspects to change predicates, 

Why does the planner have to be online?
Imagine instead of modelling the actions as probablistic, we model the uncertainty as being like another actor. Lets say we are playing soccer, impossible to write down a  plan for every possible move any player on the other team does we do this dependant on all other information. Plan would be IMMENSE, and also very computationally expensive to create.
Rather we use the planner like a coach, shouting on the sidelines and adapting what each player should do to the current situation. 

Was also thinking that the Monte Carlo Tree search might help Semir's problem of chaining actions. Might be easier to think about with a concrete chaining example

Could set it up rn, such that if gets in impossible state, it recognizes it and tries again. I think this is what I will do for now

Ok so with unstack enabled, it will never get stuck

With it disabled it crashes because it gets stuck... time to enable backtracking!!!

Ok what the fuck do I do now????

Main priority getting the backtracking to work? Ok so it works, but it doesn't prohibit that same ation b/c of environment non linearities

I think my definitions of history are the same, but I am not entirelly sure about that
